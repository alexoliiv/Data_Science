{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Iris():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    columns = ['sepal length','sepal width','petal length','petal width','class']\n",
    "    Df_Iris = pd.read_csv(url, sep= ',', header = None)\n",
    "    Df_Iris.columns = columns\n",
    "     # Printing the dataswet shape \n",
    "    print (\"Dataset Lenght: \", len(Df_Iris)) \n",
    "    print (\"Dataset Shape: \", Df_Iris.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset:\\n \",Df_Iris.head()) \n",
    "    return Df_Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_Process(df):\n",
    "    ## Convert class column to category\n",
    "    df[\"class\"] = df[\"class\"].astype('category')\n",
    "    ## Label Encoding\n",
    "    df[\"class_cat\"] = Df_Iris[\"class\"].cat.codes\n",
    "    ## Reorder Df columns\n",
    "    cols = ['sepal length','sepal width','petal length','petal width','class','class_cat']\n",
    "    df = df[cols]\n",
    "    ## Print new order\n",
    "    print(\"Dataset with columns reordered: \\n\", df.head())\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset \n",
    "def Split_Dataset(Df): \n",
    "  \n",
    "    # Seperating the target variable \n",
    "    X = Df.values[:, 0:4] \n",
    "    y = Df.values[:, -1] \n",
    "  \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, y, test_size = 0.3, random_state = 100) \n",
    "    \n",
    "    print(\"Train dataset size :\", len(X_train))\n",
    "    print(\"Test dataset size :\", len(X_test))\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with giniIndex. \n",
    "def Train_Gini(X_train, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with entropy. \n",
    "def Train_Entropy(X_train, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Df_Iris = Import_Iris()\n",
    "    Df_Iris = Pre_Process(Df_Iris)\n",
    "    X_train,X_test, y_train, y_test = Split_Dataset(Df_Iris)\n",
    "    clf_fini = Train_Gini(X_train,y_train.astype('int'))\n",
    "    clf_entropy = Train_Entropy(X_train,y_train.astype('int'))\n",
    "     # Operational Phase \n",
    "    print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test.astype('int'), y_pred_gini.astype('int')) \n",
    "      \n",
    "    print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test.astype('int'), y_pred_entropy.astype('int')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.Main Function </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght:  150\n",
      "Dataset Shape:  (150, 5)\n",
      "Dataset:\n",
      "     sepal length  sepal width  petal length  petal width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "Dataset with columns reordered: \n",
      "    sepal length  sepal width  petal length  petal width        class  \\\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa   \n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa   \n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa   \n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa   \n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa   \n",
      "\n",
      "   class_cat  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "Train dataset size : 105\n",
      "Test dataset size : 45\n",
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "[2 0 2 0 2 2 0 0 2 0 0 2 0 0 2 1 1 2 2 2 2 0 2 0 1 2 1 0 1 2 1 1 1 0 0 1 0\n",
      " 1 2 2 0 1 2 2 0]\n",
      "Confusion Matrix:  [[16  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  1 17]]\n",
      "Accuracy :  95.5555555556\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.91      0.91      0.91        11\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "[2 0 2 0 2 2 0 0 2 0 0 2 0 0 2 1 1 2 2 2 2 0 2 0 1 2 1 0 1 2 1 1 1 0 0 1 0\n",
      " 1 2 2 0 1 2 2 0]\n",
      "Confusion Matrix:  [[16  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  1 17]]\n",
      "Accuracy :  95.5555555556\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.91      0.91      0.91        11\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
