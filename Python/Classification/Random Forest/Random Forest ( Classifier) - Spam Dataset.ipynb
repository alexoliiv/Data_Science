{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Here, I'll use and random forest algorithm to classify wheter an e-mail is a spam or ham. It'll be used NLP to proccess the data, so then, we can process the data and generate the trees to classify our samples. <h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix \n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght:  5572\n",
      "Dataset Shape:  (5572, 2)\n",
      "Dataset:\n",
      "    target                                               text\n",
      "0    ham  Go until jurong point, crazy.. Available only ...\n",
      "1    ham                      Ok lar... Joking wif u oni...\n",
      "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    ham  U dun say so early hor... U c already then say...\n",
      "4    ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "Df_Sms = Import_Data(url = 'C:\\\\Users\\\\alexander.leite\\\\Desktop\\\\Machine Learning\\\\datasets\\\\spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values :\n",
      " target    0\n",
      "text      0\n",
      "dtype: int64 \n",
      "\n",
      "Data type :\n",
      " target    object\n",
      "text      object\n",
      "dtype: object \n",
      "\n",
      "Value count :\n",
      " ham     4825\n",
      "spam     747\n",
      "Name: target, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Data_Summaryze(Df_Sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  go until jurong point, crazy.. available only ...\n",
       "1    ham                      ok lar... joking wif u oni...\n",
       "2   spam  free entry in  a wkly comp to win fa cup final...\n",
       "3    ham  u dun say so early hor... u c already then say...\n",
       "4    ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_Sms['text'] = Df_Sms['text'].apply(Pre_Process_Text)\n",
    "Df_Sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape -->  (5572, 7791)\n"
     ]
    }
   ],
   "source": [
    "X = TfIdf(Df_Sms['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 7791)\n",
      "(1672, 7791)\n",
      "(3900, 1)\n",
      "(1672, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = Split_Data(X,Df_Sms.target)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.leite\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[1444    2]\n",
      " [  38  188]]\n",
      "Accuracy :  97.6076555024\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1446\n",
      "           1       0.99      0.83      0.90       226\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1672\n",
      "   macro avg       0.98      0.92      0.95      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Random_Forest(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Data(url):\n",
    "    '''\n",
    "    url = url containing the dataset location\n",
    "    Function : Import_Data()\n",
    "    Date : 15/04/2019\n",
    "    Author : Alejandro\n",
    "    Import \"url\" dataset and print a few informations about it.\n",
    "    '''\n",
    "    Df = pd.read_csv(url, sep= ',',encoding = 'latin-1')\n",
    "    Df = Df[['v1','v2']]\n",
    "    Df.columns = ['target','text']\n",
    "     # Printing the dataset shape \n",
    "    print (\"Dataset Lenght: \", len(Df)) \n",
    "    print (\"Dataset Shape: \", Df.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset:\\n \",Df.head()) \n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Summaryze(df):\n",
    "    '''\n",
    "    df = Dataset \n",
    "    Function : Data_Summaryze()\n",
    "    Date : 15/04/2019\n",
    "    Summaryze a few \"df\" informations like : null values, data types and some descriptive measures.\n",
    "    '''\n",
    "    ## Visualyze null values by columns\n",
    "    print(\"Null values :\\n\",df.isnull().sum(),'\\n')\n",
    "    ## Visualyze data types by columns\n",
    "    print(\"Data type :\\n\",df.dtypes,'\\n')\n",
    "    print(\"Value count :\\n\",df.target.value_counts(),'\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_Process_Text(str):\n",
    "    '''\n",
    "    str = dataset containing our sms\n",
    "    Function : Pre_Process_Text()\n",
    "    Date : 18/04/2019\n",
    "    Process our dataset so, our machine learning model can interpret the data properly\n",
    "    '''\n",
    "    ## lower case\n",
    "    str = str.lower()\n",
    "    ## remove numbers\n",
    "    str = re.sub(r'\\d+', '', str)\n",
    "    ## remove punctuation\n",
    "    ##str = str.translate(string.punctuation)\n",
    "    ## remove white space\n",
    "    str = str.strip()\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfIdf(corpus):\n",
    "    '''\n",
    "    str = dataset containing our sms\n",
    "    Function : TfIdf()\n",
    "    Date : 22/04/2019\n",
    "    Calculate the tfidf score for each word in our dataset\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    print(\"X shape --> \", X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Data(X,y):\n",
    "    '''\n",
    "    X = features\n",
    "    y = target\n",
    "    Function : Split_Data()\n",
    "    Date : 23/04/2019\n",
    "    encode our target variable and split our dataset\n",
    "    '''\n",
    "    Label = LabelEncoder()\n",
    "    y = Label.fit_transform(y).reshape(-1,1)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(X_train,y_train,X_test,y_test):\n",
    "    '''\n",
    "    X = features\n",
    "    y = target\n",
    "    Function : Random_Forest_Train()\n",
    "    Date : 23/04/2019\n",
    "    create our random forest to predict future values\n",
    "    '''\n",
    "    rf = RandomForestClassifier(n_estimators=50)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
